REALIZADOS:


SECCION WORD EMBEDDINGS 
1. Adicionar nombre a los datos de Peru
2. INTENTAR BATCHES MAS GRANDE (128, 256)
3. AUMENTAR EL EMBEDDING (256, 512)

SECCION CLASIFICADORES 
1. Entrenar clasificadores con la data USA (60 - 20 - 20)
2. BERT-Fine tune clasificador

SECCION METRICAS
1. KNN: 3, 5, 7 neighbours
2. LR: cost(C) -> (https://www.csie.ntu.edu.tw/~cjlin/papers/guide/guide.pdf)
3. MLP: learning rate(), regularization(alpha) -> (http://cs231n.stanford.edu/slides/2017/cs231n_2017_lecture6.pdf)[slide 77]
4. SVM - linear: cost(C) -> (https://www.csie.ntu.edu.tw/~cjlin/papers/guide/guide.pdf)
5. SVM - rbf: gamma(y), cost(C) -> (https://www.csie.ntu.edu.tw/~cjlin/papers/guide/guide.pdf)
6. anadir f1, precision y recall


PENDIENTES:

SECCION RECOLECCION DE DATOS
1. Recolectar mas datos de Peru

SECCION FURTHER IDEAS
1. Attention networks to merge text embeddings -> (https://www.aclweb.org/anthology/D18-1508.pdf)
	1.1 Attention merging local (glove, word) techniques with global (bert) techniques 
	1.2 Attention per course
	1.3 Attention per faculty with courses's code -> need a reformat in data
	1.4 https://keras.io/examples/nlp/text_classification_with_transformer/

2. Metric learning - 60 %train, 20% val, 20% test - (embeddings: stopwords or not + normalization [l2])
	links: https://github.com/KevinMusgrave/pytorch-metric-learning
		https://huggingface.co/transformers/training.html
	2.1 bert + metric learning ( freeze some layers)
	2.2 bert (as feature extraction) - mlp + metric_learnig
________________________________________________________________________________________________________
	2.2.1 l2norm -> change dimension
	2.3 try hard negative mining and semi hard negative mining
	2.4 add an autoencoder with reconstructed loss

________________________________________________________________________________________________________	
3. Augmented features 


_________________________________________________________________________________________________________
4. Analisis explicativo de resultados
	1.1 Lime technique (https://github.com/marcotcr/lime)

___________________________________________

|27 - 07 - 21
0. Transformer Layer: https://keras.io/examples/nlp/text_classification_with_transformer/
1. Attention metric-learning -> sacar los top 10 cursos con mayor attention - por categoria (igual para el word cloud). 
2. Case of Study: Peru, Chile and Brasil. Rehacer el paso 1 con los datas de Peru, Chile y Brasil.
3. Metodos explicativos
